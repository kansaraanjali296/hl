pela run thayu direct download thay che 


import os
import re
import sqlite3
import warnings
import pyodbc
import requests
import logging
from zipfile import ZipFile
from datetime import datetime
from selenium import webdriver
from selenium.webdriver import Keys
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

warnings.simplefilter("ignore")
driver = webdriver.Chrome(ChromeDriverManager().install())


def download_file_dir(url):
    # ----------------------------------------------pdf Down path --------------------------------------------#
    files_dir = os.path.expanduser('~') + "\\Documents\\" + "PythonFile\\" + url.split('://')[1].split("/")[0] + "_py\\" + 'File'

    if os.path.exists(files_dir):
        pass
    else:
        os.makedirs(files_dir)
    return files_dir


def download_pdf(links):
    all_links = links.split(',')
    if len(all_links) > 1:
        fullname = os.path.join(files_dir, datetime.now().strftime(f"%d%m%Y_%H%M%S%f") + '.zip')
        zip_obj = ZipFile(fullname, 'w')
        for pdfLink in all_links:
            # a = 'ifecarehll.com/file/'.split(".")[1].split("/")[0]

            filename = datetime.now().strftime(f"%d%m%Y_%H%M%S%f") + "." + pdfLink.split(".")[1].split("/")[0]
            response = requests.get(pdfLink)
            pdf = open(filename, 'wb')
            pdf.write(response.content)
            pdf.close()

            zip_obj.write(filename)
            os.remove(filename)
            logging.info("Zip File Downloaded")
    else:
        response = requests.get(links)
        fullname = os.path.join(files_dir, datetime.now().strftime(f"%d%m%Y_%H%M%S%f") + "." + links.split(".")[1].split("/")[0])
        pdf = open(fullname, 'wb')
        pdf.write(response.content)
        pdf.close()
        logging.info("File Downloaded")
    return fullname


try:
    url = 'http://www.lifecarehll.com/tender'

    files_dir = download_file_dir(url)
    while True:

        driver.get(url)
        print(url)

        tr_data = driver.find_elements(By.XPATH, '//*[@class="table_general"]//tbody//tr')

        del tr_data[0]
        for tr_d in tr_data:
            # t_num = tr_d.find_element(By.XPATH, ".//td[3]").text.strip()

            all_links = tr_d.find_elements(By.XPATH, './/td[2]/a')
            for i in all_links:
                i.send_keys(Keys.CONTROL + Keys.RETURN)  # open new tab and return old tab
                driver.switch_to.window(driver.window_handles[1])
                driver.implicitly_wait(10)

                Tender_Notice_No = driver.find_element(By.XPATH, '//*[@id="search_content"]/div[2]/table/tbody/tr[3]/td[2]').text.strip()
                print(Tender_Notice_No)
                Tender_Summery = driver.find_element(By.XPATH, '//*[@id="search_content"]/div[2]/table/tbody/tr[4]/td[2]').text.strip()
                Tender_Details = driver.find_element(By.XPATH, '//*[@id="search_content"]/div[4]/table/tbody/tr[2]/td[2]').text.strip()
                OpeningDate = driver.find_element(By.XPATH, '//*[@id="search_content"]/div[3]/table/tbody/tr[5]/td[2]').text.strip()
                Bid_deadline_2 = driver.find_element(By.XPATH, '//*[@id="search_content"]/div[3]/table/tbody/tr[4]/td[2]').text.strip()

                try:
                    links = []
                    links_data = driver.find_elements(By.XPATH, '//*[@class="icon_size16 icon_pdf float_left right_5"]/..')
                    if links_data == []:
                        links_data = driver.find_elements(By.XPATH, '//*[@class="icon_size16 icon_download float_left right_5"]/..')
                        if links_data == []:
                            links_data = driver.find_elements(By.XPATH, '//*[@class="icon_size16 icon_word float_left right_5"]/..')
                            if links_data == []:
                                links_data = ''
                    for lnk in links_data:
                        lnk = lnk.get_attribute('href')
                        links.append(lnk)
                    links = ', '.join(links)
                    print(links)
                    Documents_2 = download_pdf(links)

                except:
                    links_data = ''


                print("------------------------------------------------------------------------------------------------------------------")

                driver.close()
                driver.switch_to.window(driver.window_handles[0])
                driver.implicitly_wait(0.5)

        url = driver.find_element(By.XPATH, value='//*[contains(text(), "Next")]').get_attribute('href')
        # print(url)
        driver.implicitly_wait(0.5)
        if url == None:
            break


except Exception as e:
    print(e)